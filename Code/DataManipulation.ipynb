{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: File paths should be the same if you are working in the repo.\n",
    "#Also, I would push these csv's but they're bigger than the max file size lmao\n",
    "wind = xr.open_dataset('../Data/new_raw_data/agg_terraclimate_windspeed_1979_2020.nc')\n",
    "drought = xr.open_dataset('../Data/new_raw_data/Drought_PDSI_1979_2020_GLOBE.nc')\n",
    "wind.ws.to_dataframe().to_csv('../Data/new_raw_data/windspeed.csv')\n",
    "drought.PDSI.to_dataframe().to_csv('../Data/new_raw_data/drought.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_df = pd.read_csv('../data/new_raw_data/windspeed.csv')\n",
    "wind_df = np.round(wind_df, decimals=1)\n",
    "wind_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drought_df = pd.read_csv('../data/new_raw_data/drought.csv')\n",
    "drought_df = np.round(drought_df, decimals=1)\n",
    "drought_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildfire_df = pd.read_csv('../Data/Clean Data/Wildfires/cleaned_wildfires.csv')\n",
    "wildfire_df = np.round(wildfire_df, decimals=1)\n",
    "wildfire_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildfire_df['DISCOVERY_DATE'].apply(str)\n",
    "date_list = wildfire_df['DISCOVERY_DATE'].tolist()\n",
    "fire_list = []\n",
    "for i in range(len(date_list)):\n",
    "    fire_list.append(1)\n",
    "    if not date_list[i].endswith('01'):\n",
    "        date_list[i] = date_list[i][:-2] + \"01\"\n",
    "wildfire_df['time'] = date_list\n",
    "wildfire_df['fire'] = fire_list\n",
    "wildfire_df = wildfire_df.drop(['DISCOVERY_DATE'], axis=1)\n",
    "wildfire_df = wildfire_df.rename({'LATITUDE': 'lat', 'LONGITUDE': 'lon'}, axis=1)\n",
    "wildfire_df = wildfire_df[['time', 'lat', 'lon', 'fire']]\n",
    "wildfire_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(wind_df, drought_df, how='outer')\n",
    "final_df = final_df.dropna()\n",
    "final_df = pd.merge(final_df, wildfire_df, how='outer')\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df[final_df['time'].between('2000-01-01', '2015-12-01')]\n",
    "# print(final_df.dtypes)\n",
    "final_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df[final_df['ws'].notna()]\n",
    "final_df = final_df[final_df['PDSI'].notna()]\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"../Data/Clean Data/final_data.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split up the independent and dependent variables, where the independent variables are the lattitude, longitude, wind speed, and PDSI. The dependent is whether there was a fire or not\n",
    "x = final_df[['lat','lon','ws', 'PDSI']]\n",
    "y = final_df['fire']\n",
    "\n",
    "# Pick what fraction of the data you want to be the testing data\n",
    "fraction_split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into training and testing data using sklearn function train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(x,y, test_size=fraction_split)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the training and testing data to two csvs in Clean Data folder\n",
    "train_x = pd.DataFrame(train_x)\n",
    "train_y = pd.DataFrame(train_y)\n",
    "\n",
    "test_x = pd.DataFrame(test_x)\n",
    "test_y = pd.DataFrame(test_y)\n",
    "\n",
    "\n",
    "training_data = train_x.assign(fire = train_y)\n",
    "testing_data = test_x.assign(fire = test_y)\n",
    "\n",
    "print(training_data)\n",
    "training_data.to_csv(\"../Data/Clean Data/training_data.csv\", encoding='utf-8', index=False)\n",
    "testing_data.to_csv(\"../Data/Clean Data/testing_data.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
